---
title: "Heap-Based Priority Queue: Sorting the Search Space"
subtitle: "O(log n) Efficiency Through Smart Organization!"
author: "CS 101 - Fall 2025"
format:
  revealjs:
    theme: white
    highlight-style: github
    code-block-background: true
    code-block-border-left: "#31BAE9"
    slide-number: true
    chalkboard: true
    scrollable: false
    transition: none
    css: custom_big_o.css
    width: 1200
    height: 800
    margin: 0.05
---

# What is Heap-Based Priority Queue Sorting?

::: {.callout-tip icon="true"}
## The Smart Organizer üè•

**Heap-based priority queues** achieve **O(log n)** efficiency by maintaining a **partial ordering** that keeps the most important element always accessible!

**Real-World Analogy**: 

* Like an **emergency room triage system** - critical patients treated first
* **Hospital priority**: Heart attack before headache!
* **1000 patients** ‚Üí Only **10 steps** to find next priority!

:::

```python
import heapq

# Priority queue: lower number = higher priority
emergency_room = []

patients = [
    (1, "Heart Attack"),    # Highest priority
    (5, "Broken Arm"),
    (2, "Severe Bleeding"),
    (8, "Routine Checkup"), # Lowest priority
    (3, "Chest Pain"),
    (7, "Headache"),
    (1, "Stroke"),          # Also highest priority
]
```

::: {.columns}
::: {.column}
**Incredible Scaling** üìä

* 100 patients ‚Üí ~7 steps
* 1,000 patients ‚Üí ~10 steps  
* 1,000,000 patients ‚Üí ~20 steps
* **Life-saving efficiency!**

:::

::: {.column}
**Key Insight** üîë
The heap **maintains priority order** without full sorting.

**Magic Question**: 
*"Can I always access the highest priority in O(1) while maintaining order in O(log n)?"*

If yes ‚Üí Heap is perfect!
:::
:::


## What Makes Heap Sorting O(log n)?

::: {.callout-note icon="true"}
## The "Partial Ordering" Strategy üîÑ

Heaps use smart tree structure to avoid full sorting while maintaining priority access.

:::

:::: {.columns}

::: {.column width="50%"}
**Binary Min-Heap Property** üå≥
```python
# Heap maintains this invariant:
# Parent ‚â§ Children (always!)

#       1 (Heart Attack)
#      / \
#     3   2 (Severe Bleeding)  
#    / \ / \
#   8  5 7  ?

# Root = minimum priority = highest urgency
# Height = log‚ÇÇ(n) = maximum steps needed
```

**Key Properties:**
- **Parent ‚â§ Children**: Every parent node ‚â§ its children
- **Complete binary tree**: Fills left to right, level by level
- **Root = Minimum**: Smallest element always at top
:::

::: {.column width="50%"}
**Array Representation** üìä
```python
# Heap stored as compact array
Index:  0  1  2  3  4  5  6
Value: [1, 3, 2, 8, 5, 7, ?]

# Navigation formulas (no pointers needed!)
def get_parent(i):     return (i-1)//2
def get_left_child(i): return 2*i + 1  
def get_right_child(i): return 2*i + 2

# Why this works:
# - Complete tree fills left-to-right
# - Array index maps perfectly to tree position
# - O(1) parent/child access
```

**The Array Advantage:**
- **Space efficient**: No pointer overhead
- **Cache friendly**: Elements stored contiguously  
- **O(1) navigation**: Simple index arithmetic
:::

::::


## Heap Operations - The O(log n) Magic!

::: {.callout-important icon="true"}
## Heap Insertion - "Bubble Up" Strategy üìà

Adding elements maintains heap property through smart upward movement!

:::

::: {.columns}
::: {.column}
**Visual Tree Structure** üå≥
```
       1 (Heart Attack)
      / \
     3   2 (Severe Bleeding)
    / \ / \
   8  5 7  ?
```

**Key Insight**: Not fully sorted, but **minimum always accessible** in O(1)!

**The Heap Promise:**
- Always know the most urgent patient
- Insert new patients efficiently
- Remove urgent patients efficiently
:::

::: {.column}
**How `heappush()` Works** ‚¨ÜÔ∏è
```python
# Adding "Stroke" (Priority 1):

# Step 1: Insert at end of array
[1, 3, 2, 8, 5, 7] ‚Üí [1, 3, 2, 8, 5, 7, 1]

# Step 2: "Bubble Up" - Compare with parent
# 1 < 2 (parent) ‚Üí Swap!
[1, 3, 1, 8, 5, 7, 2]

# Step 3: Continue until heap property restored
# Maximum swaps: log‚ÇÇ(n) levels
# Time Complexity: O(log n)

def heappush_explained(heap, value):
    heap.append(value)        # O(1) - add to end
    bubble_up(heap, len(heap)-1)  # O(log n) - fix order
```

**Why O(log n)?**
- Tree height = log‚ÇÇ(n)
- Bubble up at most one path
- Path length ‚â§ tree height
:::
:::



## Heap Removal - The "Bubble Down" Strategy

::: {.callout-important icon="true"}
## Heap Removal - "Bubble Down" Strategy üìâ

Removing the highest priority element maintains heap property through smart downward movement!

:::

::: {.columns}
::: {.column}
**How `heappop()` Works** ‚¨áÔ∏è
```python
# Removing highest priority patient:

# Step 1: Remove root (minimum element)
Remove: 1 (Heart Attack)
Remaining: [?, 3, 1, 8, 5, 7, 2]

# Step 2: Move last element to root
[2, 3, 1, 8, 5, 7]

# Step 3: "Bubble Down" - Compare with children
# Choose smaller child and swap if needed
# 2 > 1 (smaller child) ‚Üí Swap!

def heappop_explained(heap):
    min_val = heap[0]         # O(1) - get minimum
    heap[0] = heap.pop()      # O(1) - move last to root
    bubble_down(heap, 0)      # O(log n) - fix order
    return min_val
```
:::

::: {.column}
**The Bubble Down Process** üîΩ
```python
# Visual bubble down process:
#     2              1
#    / \    ‚Üí       / \
#   3   1          3   2
#  / \ /          / \ 
# 8  5 7         8  5 7

# Step-by-step:
# 1. Compare 2 with children (3, 1)
# 2. 1 is smaller ‚Üí swap 2 and 1
# 3. Continue until heap property restored

# Maximum swaps: log‚ÇÇ(n) levels
# Time Complexity: O(log n)
```

**Why O(log n)?**
- Tree height = log‚ÇÇ(n)
- Bubble down at most one path  
- Path length ‚â§ tree height
- Each comparison is O(1)
:::
:::



## Heap vs Other Approaches - Performance Showdown!

**Performance Comparison** üìä: 
Champion-like Qualities!

::: {.columns}
::: {.column}
**Efficiency Comparison** ‚ö°

| Method | Insert | Remove Min | Total (n ops) |
|--------|--------|------------|---------------|
| **Heap** | O(log n) | O(log n) | **O(n log n)** |
| Unsorted List | O(1) | O(n) | O(n¬≤) |
| Sorted List | O(n) | O(1) | O(n¬≤) |
| Re-sort each time | O(n log n) | O(1) | **O(n¬≤ log n)** |

**The Heap Sweet Spot:**

- Balanced insert/remove performance
- Dramatically better than naive approaches
- Scales beautifully with priority data
- No need for full sorting

**Heap wins!** üèÜ
:::

::: {.column}
**When Heaps Shine** ‚ú®

```python
# Emergency room priority queue
# Even with thousands of patients!

# Real-time priority management
import heapq

# Simulation: 1000 patients arriving
patients = []
for i in range(1000):
    priority = random.randint(1, 10)
    patient = f"Patient_{i}"
    heapq.heappush(patients, (priority, patient))  # O(log n)

# Always serve highest priority first
while patients:
    priority, patient = heapq.heappop(patients)  # O(log n)
    print(f"Treating: {patient} (Priority {priority})")

# Total time: O(n log n) for n operations
# Compare with O(n¬≤) for sorting each time!

# The secret: Partial ordering pays dividends!
```
:::
:::

## Python Heap Implementation - The Efficient Choice!

::: {.callout-tip icon="true"}
## Experience the O(log n) Magic! üßë‚Äçüíª

See how Python's `heapq` module demonstrates perfect priority ordering.

:::

::: {.columns}
::: {.column}
**Emergency Room Demo** üè•
```python
import heapq
import time

# Simulate a hospital emergency room
# Priority queue: lower number = higher priority
emergency_room = []

# Add patients with priorities
patients = [
    (1, "Heart Attack"),    # Highest priority
    (5, "Broken Arm"),
    (2, "Severe Bleeding"),
    (8, "Routine Checkup"), # Lowest priority
    (3, "Chest Pain"),
    (7, "Headache"),
    (1, "Stroke"),          # Also highest priority
]

print("Adding patients to emergency queue:")
for priority, condition in patients:
    heapq.heappush(emergency_room, (priority, condition))  # O(log n)
    print(f"Added: {condition} (Priority {priority})")

print("\nTreating patients in priority order:")
while emergency_room:
    priority, condition = heapq.heappop(emergency_room)  # O(log n)
    print(f"Treating: {condition} (Priority {priority})")

# Each operation is O(log n)
# Total time: O(n log n) for n operations
# Much better than sorting repeatedly: O(n¬≤ log n)!
```
:::

::: {.column}
**Output Example** üìã
```
Adding patients to emergency queue:
Added: Heart Attack (Priority 1)
Added: Broken Arm (Priority 5)
Added: Severe Bleeding (Priority 2)
Added: Routine Checkup (Priority 8)
Added: Chest Pain (Priority 3)
Added: Headache (Priority 7)
Added: Stroke (Priority 1)

Treating patients in priority order:
Treating: Heart Attack (Priority 1)
Treating: Stroke (Priority 1)
Treating: Severe Bleeding (Priority 2)
Treating: Chest Pain (Priority 3)
Treating: Broken Arm (Priority 5)
Treating: Headache (Priority 7)
Treating: Routine Checkup (Priority 8)
```

**Perfect priority ordering without full sorting!** ‚úÖ

**Python's `heapq` Advantage:**
- Highly optimized C implementation
- Minimal memory overhead
- Simple API design
- Built-in to standard library
:::
:::



# The Math Behind Heap O(log n)

::: {.callout-note icon="true"}
## Understanding Heap Mathematics üìê

The logarithmic performance comes from the tree structure!

:::

::: {.columns}
::: {.column}
**Tree Height = log‚ÇÇ(n)** üî¢
```python
# Why heaps are O(log n)
def calculate_tree_height(n):
    import math
    return math.ceil(math.log2(n + 1))

# Examples of heap heights:
sizes = [7, 15, 31, 63, 127, 1023]
print("Elements\t\tTree Height\t\tMax Operations")
print("-" * 50)
for n in sizes:
    height = calculate_tree_height(n)
    print(f"{n}\t\t{height}\t\t\t{height}")

# Output shows logarithmic scaling!
# Elements    Tree Height    Max Operations
# 7           3              3
# 15          4              4  
# 31          5              5
# 63          6              6
# 127         7              7
# 1023        10             10

# Even 1000+ elements need only ~10 operations!
```
:::

::: {.column}
**Each Operation = One Tree Path** ‚ú®
```python
# Bubble up/down traverse exactly one path
def bubble_up_steps(heap_size):
    import math
    return math.ceil(math.log2(heap_size + 1))

# Real performance examples:
sizes = [100, 1000, 10000, 100000, 1000000]

print("Heap Size\t\tMax Steps")
print("-" * 30)
for n in sizes:
    steps = bubble_up_steps(n)
    print(f"{n:,}\t\t{steps}")

# Output:
# Heap Size    Max Steps
# 100          7
# 1,000        10
# 10,000       14
# 100,000      17
# 1,000,000    20

# Notice: Steps grow very slowly!
# This is the power of O(log n)
```
:::
:::



## Key Insights: How Heap Sorts Search Space

::: {.callout-important icon="true"}
## Heap's Sorting Philosophy üß†

Heaps achieve O(log n) through **structural invariants** rather than full sorting!

:::

:::: {.columns}

::: {.column width="50%"}
**Partial Ordering Strategy** üìä

- **Not fully sorted** like array
- **Maintains heap invariant**: parent ‚â§ children
- **Lazy sorting**: Only ensures minimum is accessible
- **Smart organization**: Structure enables fast access

**The Key Insight:**

- Full sorting is O(n log n) once
- Heap operations are O(log n) always
- Perfect for dynamic priority management
:::

::: {.column width="50%"}
**Efficient Operations** ‚ö°

- **O(log n) insertions**: Bubble up one path
- **O(log n) deletions**: Bubble down one path
- **O(1) minimum access**: Always at root
- **Space efficient**: Array-based, no pointers

**Path-Based Efficiency:**

- Tree height limits operation cost
- Each operation follows one root-to-leaf path
- Path length = tree height = O(log n)
- **Structure inherently limits complexity!**
:::

::::

## Real-World Heap Applications

::: {.callout-tip icon="true"}
## Where You Use Heaps Every Day! üåç

Heap-based priority queues power many systems you interact with daily.

:::

::: {.columns}
::: {.column}
**System-Level Applications** üíª
```python
# Operating system task scheduling
# CPU scheduler uses priority heaps
class TaskScheduler:
    def __init__(self):
        self.tasks = []  # Min-heap by priority
    
    def add_task(self, priority, task):
        heapq.heappush(self.tasks, (priority, task))  # O(log n)
    
    def get_next_task(self):
        return heapq.heappop(self.tasks)[1]  # O(log n)

# Network packet routing
# Routers prioritize urgent packets first

# Graphics rendering
# Z-buffer algorithms use priority queues

# Database query optimization
# Query planners use heaps for join ordering
```
:::

::: {.column}
**Algorithm Applications** üßÆ
```python
# Dijkstra's shortest path algorithm
# Google Maps, GPS navigation
def dijkstra_shortest_path(graph, start):
    distances = {node: float('inf') for node in graph}
    distances[start] = 0
    pq = [(0, start)]  # Priority queue: (distance, node)
    
    while pq:
        current_dist, current = heapq.heappop(pq)  # O(log n)
        
        for neighbor, weight in graph[current]:
            distance = current_dist + weight
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(pq, (distance, neighbor))  # O(log n)

# Huffman coding (file compression)
# Event simulation systems
# A* pathfinding in games
# Machine learning (beam search)
```
:::
:::

**Any scenario needing efficient priority-based access leverages heaps!**

## Summary: Heap-Based Priority Queues - The Smart Organizer!

::: {.callout-tip icon="true"}
## Key Takeaways üéØ

**Heap-based priority queues** achieve O(log n) through smart **partial ordering**!

:::

::: {.columns}
::: {.column}
**What Makes Heaps Special**

- üè• **Perfect for priorities** - always know the most urgent
- üå≥ **Smart tree structure** - height limits operation cost
- ‚öñÔ∏è **Balanced performance** - O(log n) insert AND remove
- üöÄ **Incredible scaling** - millions of items, ~20 operations max

**Python Heap Champions:**

- Emergency room triage: `heapq` module
- Task scheduling: priority queues
- Pathfinding: Dijkstra's algorithm
- System optimization: balanced performance
:::

::: {.column}
**Programming Wisdom** üí≠
```python
# When to choose heaps:

# For priority-based processing
import heapq
heapq.heappush(tasks, (priority, task))    # O(log n)
next_task = heapq.heappop(tasks)           # O(log n)

# For "top-k" problems  
# Find k largest/smallest items efficiently

# For dynamic ordering with frequent updates
# Better than re-sorting: O(log n) vs O(n log n)

# Remember the trade-off:
# - O(1): Hash tables, direct access
# - O(log n): Heaps, trees - organized data  
# - O(n): Linear search - no organization needed

# Choose heaps when you need efficient priority access!
```
:::
:::



## Concluding Thoughts {.center}

::: {.callout-important icon="true"}
**Key Takeaway**: Heaps sort the search space through **partial ordering** and **structural invariants**, achieving O(log n) efficiency without full sorting!

The magic is in the **tree height** - it inherently limits the number of operations needed! üå≥
:::

::: {style="color: #2E86C1; font-size: 0.9em; text-align: center; margin-top: 0.5em;"}
üöÄ Ready to implement your own priority systems with O(log n) efficiency! ‚ö°
:::